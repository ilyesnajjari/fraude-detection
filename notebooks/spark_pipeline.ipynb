{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21376a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç V√©rification des microservices :\n",
      "‚úÖ ingestion-service OK : {'status': 'ingestion-service running'}\n",
      "‚úÖ train-service OK : {'status': 'train-service running'}\n",
      "‚ùå predict-service erreur : ('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))\n",
      "‚úÖ compare-service OK : {'detail': 'Not Found'}\n",
      "‚ùå Erreur r√©cup√©ration features : ('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))\n",
      "\n",
      "üöÄ Lancement du pipeline Spark...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/02 13:23:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Time: double (nullable = true)\n",
      " |-- V1: double (nullable = true)\n",
      " |-- V2: double (nullable = true)\n",
      " |-- V3: double (nullable = true)\n",
      " |-- V4: double (nullable = true)\n",
      " |-- V5: double (nullable = true)\n",
      " |-- V6: double (nullable = true)\n",
      " |-- V7: double (nullable = true)\n",
      " |-- V8: double (nullable = true)\n",
      " |-- V9: double (nullable = true)\n",
      " |-- V10: double (nullable = true)\n",
      " |-- V11: double (nullable = true)\n",
      " |-- V12: double (nullable = true)\n",
      " |-- V13: double (nullable = true)\n",
      " |-- V14: double (nullable = true)\n",
      " |-- V15: double (nullable = true)\n",
      " |-- V16: double (nullable = true)\n",
      " |-- V17: double (nullable = true)\n",
      " |-- V18: double (nullable = true)\n",
      " |-- V19: double (nullable = true)\n",
      " |-- V20: double (nullable = true)\n",
      " |-- V21: double (nullable = true)\n",
      " |-- V22: double (nullable = true)\n",
      " |-- V23: double (nullable = true)\n",
      " |-- V24: double (nullable = true)\n",
      " |-- V25: double (nullable = true)\n",
      " |-- V26: double (nullable = true)\n",
      " |-- V27: double (nullable = true)\n",
      " |-- V28: double (nullable = true)\n",
      " |-- Amount: double (nullable = true)\n",
      " |-- Class: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|Class| count|\n",
      "+-----+------+\n",
      "|    1|   492|\n",
      "|    0|284315|\n",
      "+-----+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/02 13:26:20 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
      "|summary|              Time|                  V1|                  V2|                  V3|                  V4|                  V5|                  V6|                  V7|                  V8|                  V9|                 V10|                 V11|                 V12|                 V13|                 V14|                 V15|                 V16|                 V17|                 V18|                 V19|                 V20|                 V21|                 V22|                V23|                 V24|                 V25|                 V26|                 V27|                 V28|           Amount|               Class|\n",
      "+-------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
      "|  count|            284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|             284807|              284807|              284807|              284807|              284807|              284807|           284807|              284807|\n",
      "|   mean| 94813.85957508067|2.235360406313924...|6.865749819392767...|-5.82471054445228...|2.011824365682531...|3.704311530463074...|1.140033807220101...|-1.14961392324716...|-2.9538691083434E-16|-2.08207854988096...|2.145945990061367...|-1.27734880360795...|-3.30833340134460...|1.034652530922445...|1.708454024825641...|5.933285192758958...|1.394705224939437...|-2.87403480811790...|1.749967860942900...|9.38053027649593E-16|3.81607955077877E-16|2.850084518050253...|-7.66409282164773...|2.9538691083434E-16|4.454953538333312...|1.034652530922445...|1.808246900107513...|-3.52368642620288...|-1.13364706320206...| 88.3496192509521|0.001727485630620034|\n",
      "| stddev|47488.145954566324|  1.9586958038574904|  1.6513085794769997|  1.5162550051777732|   1.415868574940927|   1.380246734031437|  1.3322710897575714|  1.2370935981826632|  1.1943529026692048|  1.0986320892243222|  1.0888497654025215|  1.0207130277115581|  0.9992013895301415|  0.9952742301251558|  0.9585956112570617|  0.9153160116104389|  0.8762528873883704|    0.84933706367439|  0.8381762095288453|  0.8140405007685797|  0.7709250248871159|  0.7345240143713125|  0.7257015604409107| 0.6244602955949898|  0.6056470678271603|  0.5212780705409427| 0.48222701326105666|  0.4036324949650313| 0.33008326416025036|250.1201092401885|0.041527189635464985|\n",
      "|    min|               0.0|    -56.407509631329|   -72.7157275629303|   -48.3255893623954|   -5.68317119816995|   -113.743306711146|   -26.1605059358433|   -43.5572415712451|   -73.2167184552674|   -13.4340663182301|   -24.5882624372475|   -4.79747346479757|   -18.6837146333443|   -5.79188120632084|   -19.2143254902614|   -4.49894467676621|   -14.1298545174931|   -25.1627993693248|   -9.49874592104677|   -7.21352743017759|    -54.497720494566|   -34.8303821448146|    -10.933143697655|  -44.8077352037913|   -2.83662691870341|   -10.2953970749851|   -2.60455055280817|   -22.5656793207827|   -15.4300839055349|              0.0|                   0|\n",
      "|    max|          172792.0|    2.45492999121121|    22.0577289904909|    9.38255843282114|    16.8753440335975|    34.8016658766686|    73.3016255459646|    120.589493945238|    20.0072083651213|    15.5949946071278|    23.7451361206545|    12.0189131816199|     7.8483920756446|    7.12688295859376|    10.5267660517847|    8.87774159774277|    17.3151115176278|    9.25352625047285|    5.04106918541184|    5.59197142733558|    39.4209042482199|    27.2028391573154|    10.5030900899454|   22.5284116897749|    4.58454913689817|    7.51958867870916|     3.5173456116238|    31.6121981061363|    33.8478078188831|         25691.16|                   1|\n",
      "+-------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/02 13:29:05 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà R√©sultats des mod√®les :\n",
      "LogisticRegression:\n",
      "  auc: 0.9560\n",
      "  accuracy: 0.9992\n",
      "  recall: 0.9999\n",
      "  precision: 0.9993\n",
      "  training_time: 235.5118\n",
      "RandomForest:\n",
      "  auc: 0.9698\n",
      "  accuracy: 0.9993\n",
      "  recall: 0.9998\n",
      "  precision: 0.9995\n",
      "  training_time: 233.6377\n",
      "\n",
      "üì¨ R√©ponse du compare-service : {'status': 'ok', 'message': 'R√©sultats re√ßus'}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# === Chemin vers les modules personnalis√©s ===\n",
    "sys.path.append(\"../scripts\")  # ou chemin absolu\n",
    "\n",
    "# === Import des fonctions Spark ===\n",
    "from spark_pipeline import load_data, preprocess, run_all_models\n",
    "\n",
    "# === URLs des microservices ===\n",
    "INGESTION_URL = \"http://localhost:8001\"\n",
    "TRAIN_URL = \"http://localhost:8002\"\n",
    "PREDICT_URL = \"http://localhost:8003\"\n",
    "COMPARE_URL = \"http://localhost:8004\"\n",
    "\n",
    "# === V√©rification de l'√©tat des microservices ===\n",
    "print(\"\\nüîç V√©rification des microservices :\")\n",
    "for name, url in [\n",
    "    (\"ingestion-service\", INGESTION_URL),\n",
    "    (\"train-service\", TRAIN_URL),\n",
    "    (\"predict-service\", PREDICT_URL),\n",
    "    (\"compare-service\", COMPARE_URL)\n",
    "]:\n",
    "    try:\n",
    "        res = requests.get(f\"{url}/status\")\n",
    "        print(f\"‚úÖ {name} OK :\", res.json())\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {name} erreur :\", e)\n",
    "\n",
    "# === Exemple : r√©cup√©ration des features du predict-service ===\n",
    "try:\n",
    "    features_res = requests.get(f\"{PREDICT_URL}/features\")\n",
    "    print(\"\\nüìä Features du predict-service :\", features_res.json())\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Erreur r√©cup√©ration features :\", e)\n",
    "\n",
    "# === Pipeline Spark ===\n",
    "\n",
    "print(\"\\nüöÄ Lancement du pipeline Spark...\\n\")\n",
    "\n",
    "# 1. Chargement des donn√©es\n",
    "spark, df = load_data(\"../data/creditcard.csv\")\n",
    "\n",
    "# 2. Analyse rapide\n",
    "df.printSchema()\n",
    "df.groupBy(\"Class\").count().show()\n",
    "df.describe().show()\n",
    "\n",
    "# 3. Pr√©paration et split\n",
    "df_prepared = preprocess(df)\n",
    "train, test = df_prepared.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# 4. Entra√Ænement et √©valuation\n",
    "results = run_all_models(train, test)\n",
    "\n",
    "# 5. Affichage des r√©sultats\n",
    "print(\"\\nüìà R√©sultats des mod√®les :\")\n",
    "for model, metrics in results.items():\n",
    "    print(f\"{model}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value:.4f}\" if isinstance(value, float) else f\"  {metric}: {value}\")\n",
    "\n",
    "# 6. Sauvegarde de toutes les m√©triques dans le CSV\n",
    "all_metrics = []\n",
    "for model, metrics in results.items():\n",
    "    row = {\"model\": model}\n",
    "    row.update(metrics)\n",
    "    all_metrics.append(row)\n",
    "df_results = pd.DataFrame(all_metrics)\n",
    "df_results.to_csv(\"../models/resultats_auc.csv\", index=False)  # Toutes les colonnes sont sauvegard√©es\n",
    "\n",
    "    \n",
    "# 8. Fermeture de la session Spark\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "673b45f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  summary           Time            V1            V2            V3  \\\n",
      "0   count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05   \n",
      "1    mean   94813.859575  2.235360e-15  6.865750e-17 -5.824711e-15   \n",
      "2  stddev   47488.145955  1.958696e+00  1.651309e+00  1.516255e+00   \n",
      "3     min       0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01   \n",
      "4     max  172792.000000  2.454930e+00  2.205773e+01  9.382558e+00   \n",
      "\n",
      "             V4            V5            V6            V7            V8  ...  \\\n",
      "0  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  ...   \n",
      "1  2.011824e-15  3.704312e-15  1.140034e-15 -1.149614e-16 -2.953869e-16  ...   \n",
      "2  1.415869e+00  1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  ...   \n",
      "3 -5.683171e+00 -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01  ...   \n",
      "4  1.687534e+01  3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  ...   \n",
      "\n",
      "            V21           V22           V23           V24           V25  \\\n",
      "0  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
      "1  2.850085e-16 -7.664093e-16  2.953869e-16  4.454954e-15  1.034653e-15   \n",
      "2  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01  5.212781e-01   \n",
      "3 -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00 -1.029540e+01   \n",
      "4  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00  7.519589e+00   \n",
      "\n",
      "            V26           V27           V28         Amount          Class  \n",
      "0  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000  284807.000000  \n",
      "1  1.808247e-15 -3.523686e-16 -1.133647e-16      88.349619       0.001727  \n",
      "2  4.822270e-01  4.036325e-01  3.300833e-01     250.120109       0.041527  \n",
      "3 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000       0.000000  \n",
      "4  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000       1.000000  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# D√©marre Spark (si pas d√©j√† fait)\n",
    "spark = SparkSession.builder.appName(\"TrainLogisticModel\").getOrCreate()\n",
    "\n",
    "# Charge les donn√©es\n",
    "df = spark.read.csv(\"../data/creditcard.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Pr√©paration des features\n",
    "features = [\n",
    "    \"Time\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\", \"V7\", \"V8\", \"V9\", \"V10\",\n",
    "    \"V11\", \"V12\", \"V13\", \"V14\", \"V15\", \"V16\", \"V17\", \"V18\", \"V19\", \"V20\",\n",
    "    \"V21\", \"V22\", \"V23\", \"V24\", \"V25\", \"V26\", \"V27\", \"V28\", \"Amount\"\n",
    "]\n",
    "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "df_prepared = assembler.transform(df).select(\"features\", \"Class\")\n",
    "train, test = df_prepared.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Entra√Ænement du mod√®le\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"Class\")\n",
    "model = lr.fit(train)\n",
    "\n",
    "# Sauvegarde des statistiques du dataset\n",
    "desc_pd = df.describe().toPandas()\n",
    "desc_pd.to_csv(\"../models/summary_stats.csv\", index=False)\n",
    "\n",
    "# Affiche les stats pour v√©rification\n",
    "summary = pd.read_csv(\"../models/summary_stats.csv\")\n",
    "print(summary)\n",
    "\n",
    "# Sauvegarde du mod√®le (en supprimant l'ancien dossier si besoin)\n",
    "model_path = \"../models/spark_logistic_model\"\n",
    "if os.path.exists(model_path):\n",
    "    shutil.rmtree(model_path)\n",
    "model.save(model_path)\n",
    "\n",
    "# (optionnel) spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5bf6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "model_path = \"../models/spark_logistic_model\"\n",
    "if os.path.exists(model_path):\n",
    "    shutil.rmtree(model_path)\n",
    "\n",
    "model.save(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
